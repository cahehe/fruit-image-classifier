{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"elapsed":57398,"status":"ok","timestamp":1760544210295,"user":{"displayName":"Carlos","userId":"17576890038933523144"},"user_tz":240},"id":"NvKsIOeiyNnM","outputId":"975fe1ad-7a58-4f57-9aec-3407fc1b0154"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/Projects/Fruits Image Classifier/fruit-image-classifier\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Colab Notebooks/Projects/Fruits Image Classifier/fruit-image-classifier'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd /content/drive/MyDrive/Colab Notebooks/Projects/Fruits Image Classifier/fruit-image-classifier\n","%pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZIglq_PpxPsG","lines_to_next_cell":2,"outputId":"ca656f40-2635-4ac4-97d2-6dd0339c7ed8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration step\n","Using device: cpu\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["loaded existing ckpt\n","start_epoch:2 best_val_acc:0.9691283778365809\n","Resuming from checkpoint. start_epoch=2, best_val_acc=0.9691\n","Training Epoch. Values so far - Running Loss: 2.2227, Running Corrects: 64.0000, Total: 64\n","Training Epoch. Values so far - Running Loss: 4.5240, Running Corrects: 128.0000, Total: 128\n","Training Epoch. Values so far - Running Loss: 9.5857, Running Corrects: 192.0000, Total: 192\n","Training Epoch. Values so far - Running Loss: 13.9870, Running Corrects: 256.0000, Total: 256\n","Training Epoch. Values so far - Running Loss: 16.4158, Running Corrects: 320.0000, Total: 320\n","Training Epoch. Values so far - Running Loss: 19.3238, Running Corrects: 383.0000, Total: 384\n","Training Epoch. Values so far - Running Loss: 23.8774, Running Corrects: 447.0000, Total: 448\n","Training Epoch. Values so far - Running Loss: 25.3425, Running Corrects: 511.0000, Total: 512\n","Training Epoch. Values so far - Running Loss: 32.1809, Running Corrects: 573.0000, Total: 576\n","Training Epoch. Values so far - Running Loss: 33.7127, Running Corrects: 637.0000, Total: 640\n","Training Epoch. Values so far - Running Loss: 37.4361, Running Corrects: 701.0000, Total: 704\n","Training Epoch. Values so far - Running Loss: 40.2289, Running Corrects: 765.0000, Total: 768\n","Training Epoch. Values so far - Running Loss: 42.5968, Running Corrects: 829.0000, Total: 832\n","Training Epoch. Values so far - Running Loss: 44.6505, Running Corrects: 893.0000, Total: 896\n","Training Epoch. Values so far - Running Loss: 47.8486, Running Corrects: 957.0000, Total: 960\n","Training Epoch. Values so far - Running Loss: 51.4692, Running Corrects: 1021.0000, Total: 1024\n","Training Epoch. Values so far - Running Loss: 54.3120, Running Corrects: 1084.0000, Total: 1088\n","Training Epoch. Values so far - Running Loss: 62.1206, Running Corrects: 1146.0000, Total: 1152\n","Training Epoch. Values so far - Running Loss: 63.7989, Running Corrects: 1210.0000, Total: 1216\n","Training Epoch. Values so far - Running Loss: 66.6350, Running Corrects: 1274.0000, Total: 1280\n","Training Epoch. Values so far - Running Loss: 70.9766, Running Corrects: 1337.0000, Total: 1344\n","Training Epoch. Values so far - Running Loss: 73.4738, Running Corrects: 1400.0000, Total: 1408\n","Training Epoch. Values so far - Running Loss: 76.5930, Running Corrects: 1464.0000, Total: 1472\n"]}],"source":["# resnet_fruits_training.py\n","# Fine-tune ResNet-50 on Fruits-360 (or similar) using labels CSV metadata.\n","# - Expects a labels CSV with columns: split (train/test) or separate train/test CSVs\n","# - Produces checkpoints and prints training/validation metrics\n","import os\n","import glob\n","from pathlib import Path\n","import pandas as pd\n","from PIL import Image\n","import logging\n","import traceback\n","from collections import OrderedDict\n","import types\n","import __main__\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from sklearn.model_selection import train_test_split\n","\n","# ---------------------- Dataset ----------------------\n","class FruitDataset(Dataset):\n","    \"\"\"\n","    DataFrame expected columns:\n","      - 'relative_path' or 'filename' (path relative to ROOT_IMAGE_DIR)\n","      - 'label_id' or 'label_index' (integer class)\n","      - optionally 'split'\n","    \"\"\"\n","    def __init__(self, df, root_dir, transform=None, path_col=\"relative_path\", label_col=\"label_id\"):\n","        self.df = df.reset_index(drop=True)\n","        self.root_dir = Path(root_dir)\n","        self.transform = transform\n","        self.path_col = path_col\n","        self.label_col = label_col\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        rel_path = row[self.path_col]\n","        image_path = self.root_dir.joinpath(rel_path)\n","        # Robust open\n","        with Image.open(image_path) as im:\n","            im = im.convert(\"RGB\")\n","            if self.transform:\n","                im = self.transform(im)\n","        label = int(row[self.label_col])\n","        return im, label\n","\n","# ---------------------- Helpers: checkpoints ----------------------\n","def save_checkpoint(state, path):\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","    torch.save(state, path)\n","\n","def find_latest_checkpoint(folder):\n","    latest = os.path.join(folder, \"latest.pth\")\n","    if os.path.exists(latest):\n","        return latest\n","    files = glob.glob(os.path.join(folder, \"*.pth\"))\n","    if not files:\n","        return None\n","    files = sorted(files, key=os.path.getmtime, reverse=True)\n","    return files[0]\n","\n","def load_checkpoint(path, model, optimizer=None, scheduler=None, device=torch.device(\"cpu\")):\n","    # ensure dummy logger to allow unpickling if needed\n","    if not hasattr(__main__, \"logger\"):\n","        __main__.logger = types.SimpleNamespace(\n","            info=lambda *a, **k: None,\n","            warning=lambda *a, **k: None,\n","            debug=lambda *a, **k: None\n","        )\n","\n","    try:\n","        ckpt = torch.load(path, map_location=device)\n","    except Exception as e:\n","        print(f\"Warning: torch.load failed ({e}), retrying with dummy logger...\")\n","        __main__.logger = types.SimpleNamespace(\n","            info=lambda *a, **k: None,\n","            warning=lambda *a, **k: None,\n","            debug=lambda *a, **k: None\n","        )\n","        ckpt = torch.load(path, map_location=device)\n","\n","    # Extract state dict from checkpoint\n","    state = ckpt.get(\"model_state_dict\", ckpt)\n","\n","    # Strip 'module.' prefix if saved with DataParallel\n","    new_state = OrderedDict()\n","    for k, v in state.items():\n","        name = k\n","        if k.startswith(\"module.\"):\n","            name = k[len(\"module.\"):]\n","        new_state[name] = v\n","\n","    # Load weights into the model\n","    model.load_state_dict(new_state, strict=False)\n","\n","    # Optionally load optimizer state\n","    if optimizer is not None and \"optimizer_state_dict\" in ckpt:\n","        try:\n","            optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n","        except Exception as e:\n","            print(\"Could not load optimizer state:\", e)\n","\n","    # Optionally load scheduler state\n","    if scheduler is not None and \"scheduler_state_dict\" in ckpt and ckpt[\"scheduler_state_dict\"] is not None:\n","        try:\n","            scheduler.load_state_dict(ckpt[\"scheduler_state_dict\"])\n","        except Exception as e:\n","            print(\"Could not load scheduler state:\", e)\n","\n","    start_epoch = ckpt.get(\"epoch\", 0)\n","    best_val_acc = ckpt.get(\"best_val_acc\", 0.0)\n","    return start_epoch, best_val_acc\n","\n","# ---------------------- Training / Eval functions ----------------------\n","def train_one_epoch(model, loader, optimizer, criterion, device):\n","    model.train()\n","    running_loss = 0.0\n","    running_corrects = 0\n","    total = 0\n","    for imgs, labels in loader:\n","        imgs = imgs.to(device, non_blocking=True)\n","        labels = labels.to(device, non_blocking=True)\n","\n","        outputs = model(imgs)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * imgs.size(0)\n","        preds = outputs.argmax(dim=1)\n","        running_corrects += (preds == labels).sum().item()\n","        total += imgs.size(0)\n","        print(f\"Training Epoch. Values so far - Running Loss: {running_loss:.4f}, Running Corrects: {running_corrects:.4f}, Total: {total}\")\n","\n","    epoch_loss = running_loss / total\n","    epoch_acc = running_corrects / total\n","    print(f\"Training Epoch finished - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n","    return epoch_loss, epoch_acc\n","\n","def eval_one_epoch(model, loader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    running_corrects = 0\n","    total = 0\n","    with torch.no_grad():\n","        for imgs, labels in loader:\n","            imgs = imgs.to(device, non_blocking=True)\n","            labels = labels.to(device, non_blocking=True)\n","\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * imgs.size(0)\n","            preds = outputs.argmax(dim=1)\n","            running_corrects += (preds == labels).sum().item()\n","            total += imgs.size(0)\n","            print(f\"Evaluating Epoch. Values so far - Running Loss: {running_loss:.4f}, Running Corrects: {running_corrects:.4f}, Total: {total}\")\n","\n","    print(f\"Eval Epoch finished - Running_loss: {running_loss:.4f}, Running_corrects: {running_corrects:.4f}, Total: {total:.4f}\")\n","    return running_loss / total, running_corrects / total\n","\n","def main():\n","    # ---------------------- Configuration ----------------------\n","    print(\"Configuration step\")\n","    ROOT_IMAGE_DIR = \"/content/drive/MyDrive/Colab Notebooks/Projects/Fruits Image Classifier/Fruits-360/fruits-360_100x100/fruits-360\"\n","    LABELS_CSV = \"/content/drive/MyDrive/Colab Notebooks/Projects/Fruits Image Classifier/fruit-image-classifier/labels.csv\"\n","    CLASSES_CSV = \"/content/drive/MyDrive/Colab Notebooks/Projects/Fruits Image Classifier/fruit-image-classifier/classes.csv\"\n","    OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/Projects/Fruits Image Classifier/fruit-image-classifier\"\n","    '''ROOT_IMAGE_DIR = \"/Users/carloshehe/Desktop/Fruits-360/fruits-360_100x100/fruits-360\"\n","    LABELS_CSV = \"/Users/carloshehe/Desktop/Projects/fruit-image-classifier/labels.csv\"\n","    CLASSES_CSV = \"/Users/carloshehe/Desktop/Projects/fruit-image-classifier/classes.csv\"\n","    OUTPUT_DIR = \"/Users/carloshehe/Desktop/Projects/fruit-image-classifier\"'''\n","    os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","    BATCH_SIZE = 64\n","    NUM_WORKERS = 4\n","    NUM_EPOCHS = 8\n","    LEARNING_RATE = 1e-3\n","    WEIGHT_DECAY = 1e-4\n","    IMAGE_SIZE = 224  # ResNet default\n","\n","    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"Using device:\", DEVICE)\n","\n","    # ImageNet mean/std (pretrained ResNet expects these)\n","    IMAGENET_MEAN = [0.485, 0.456, 0.406]\n","    IMAGENET_STD  = [0.229, 0.224, 0.225]\n","\n","    # ---------------------- Logging ----------------------\n","    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")\n","    logger = logging.getLogger(\"train\")\n","\n","    # ---------------------- Transforms ----------------------\n","    train_transform = transforms.Compose([\n","        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(10),\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n","        transforms.ToTensor(),\n","        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n","    ])\n","\n","    val_transform = transforms.Compose([\n","        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n","    ])\n","\n","    # ---------------------- Load CSV and split ----------------------\n","    df = pd.read_csv(LABELS_CSV)\n","    logger.info(f\"Loaded labels CSV with columns: {df.columns.tolist()} (rows={len(df)})\")\n","\n","    # candidate column names\n","    path_col_candidates = ['relative_path', 'filename', 'file_name', 'path']\n","    label_col_candidates = ['label_id', 'label_index', 'label', 'class_index']\n","\n","    path_col = next((c for c in path_col_candidates if c in df.columns), None)\n","    label_col = next((c for c in label_col_candidates if c in df.columns), None)\n","\n","    if path_col is None or label_col is None:\n","        raise ValueError(f\"Could not find path or label column. CSV columns: {df.columns.tolist()}\")\n","\n","    logger.info(f\"Using path_col='{path_col}', label_col='{label_col}'\")\n","\n","    # If 'split' exists, normalize and use it; otherwise do stratified split\n","    if 'split' in df.columns:\n","        df['split_norm'] = df['split'].astype(str).str.strip().str.lower()\n","        def map_split(s):\n","            if s.startswith('train'):\n","                return 'train'\n","            if s.startswith('test'):\n","                return 'test'\n","            if s in ['val', 'valid', 'validation']:\n","                return 'val'\n","            return s\n","        df['split_norm'] = df['split_norm'].apply(map_split)\n","        logger.info(f\"Split value counts (normalized):\\n{df['split_norm'].value_counts()}\")\n","        if 'train' in df['split_norm'].values or 'test' in df['split_norm'].values or 'val' in df['split_norm'].values:\n","            train_df = df[df['split_norm'] == 'train'].reset_index(drop=True)\n","            val_df = df[df['split_norm'].isin(['test', 'val'])].reset_index(drop=True)\n","            # optional: if there is also explicit 'test' split and it's separate, you can load it here\n","            test_df = df[df['split_norm'] == 'test'].reset_index(drop=True)\n","        else:\n","            logger.warning(\"split column present but not standard; falling back to stratified split.\")\n","            train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[label_col], random_state=42)\n","            train_df = train_df.reset_index(drop=True)\n","            val_df = val_df.reset_index(drop=True)\n","            test_df = pd.DataFrame([], columns=df.columns)\n","    else:\n","        logger.info(\"No 'split' column found â€” performing a stratified train/val split (80/20).\")\n","        train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[label_col], random_state=42)\n","        train_df = train_df.reset_index(drop=True)\n","        val_df = val_df.reset_index(drop=True)\n","        test_df = pd.DataFrame([], columns=df.columns)\n","\n","    # If test_df empty, you can set it equal to val_df or leave it empty - here we keep it empty if not provided.\n","    logger.info(f\"Train samples: {len(train_df)}, Val samples: {len(val_df)}, Test samples: {len(test_df)}\")\n","\n","    # ---------------------- Build datasets / loaders ----------------------\n","    train_ds = FruitDataset(train_df, ROOT_IMAGE_DIR, transform=train_transform, path_col=path_col, label_col=label_col)\n","    val_ds   = FruitDataset(val_df,   ROOT_IMAGE_DIR, transform=val_transform,   path_col=path_col, label_col=label_col)\n","    test_ds  = FruitDataset(test_df,  ROOT_IMAGE_DIR, transform=val_transform,   path_col=path_col, label_col=label_col) if len(test_df)>0 else None\n","\n","    # guard\n","    if len(train_ds) == 0:\n","        raise ValueError(\"Training dataset is empty. Check LABELS_CSV and 'split' values.\")\n","\n","    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=(DEVICE.type=='cuda'))\n","    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=(DEVICE.type=='cuda'))\n","    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=(DEVICE.type=='cuda')) if test_ds is not None else None\n","\n","    # ---------------------- Model setup ----------------------\n","    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n","    num_ftrs = model.fc.in_features\n","    # num classes\n","    NUM_CLASSES = int(df[label_col].nunique())\n","    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n","    model = model.to(DEVICE)\n","\n","    # ---------------------- Optionally freeze backbone ----------------------\n","    def set_parameter_requires_grad(model, feature_extracting=True):\n","        if feature_extracting:\n","            for param in model.parameters():\n","                param.requires_grad = False\n","            for param in model.fc.parameters():\n","                param.requires_grad = True\n","\n","    FEATURE_EXTRACT = True\n","    set_parameter_requires_grad(model, feature_extracting=FEATURE_EXTRACT)\n","\n","    # ---------------------- Loss, Optimizer, Scheduler ----------------------\n","    criterion = nn.CrossEntropyLoss()\n","    params_to_update = [p for p in model.parameters() if p.requires_grad]\n","    optimizer = optim.AdamW(params_to_update, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n","# ---------------------- Resume / checkpoint setup ----------------------\n","    start_epoch = 0\n","    best_val_acc = 0.0\n","    ckpt = find_latest_checkpoint(OUTPUT_DIR)\n","    if ckpt:\n","        try:\n","            print(\"loaded existing ckpt\")\n","            start_epoch, best_val_acc = load_checkpoint(ckpt, model, optimizer=optimizer, scheduler=scheduler, device=DEVICE)\n","            print(\"start_epoch:{} best_val_acc:{}\".format(start_epoch, best_val_acc))\n","            #logger.info(f\"Resuming from checkpoint. start_epoch={start_epoch}, best_val_acc={best_val_acc:.4f}\")\n","            print(f\"Resuming from checkpoint. start_epoch={start_epoch}, best_val_acc={best_val_acc:.4f}\")\n","        except Exception as e:\n","            logger.warning(f\"Failed to load checkpoint {ckpt}: {e}\\nStarting from scratch.\")\n","\n","    # ---------------------- Training loop ----------------------\n","    try:\n","        for epoch in range(start_epoch, NUM_EPOCHS):\n","            train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n","\n","            # Optional quick eval on training set for sanity-check (small overhead)\n","            train_eval_loss, train_eval_acc = eval_one_epoch(model, train_loader, criterion, DEVICE)\n","\n","            val_loss, val_acc = eval_one_epoch(model, val_loader, criterion, DEVICE)\n","\n","            scheduler.step()\n","\n","            logger.info(f\"Epoch {epoch+1}/{NUM_EPOCHS}  train_loss={train_loss:.4f} train_acc={train_acc:.4f}  \"\n","                        f\"eval_train_loss={train_eval_loss:.4f} eval_train_acc={train_eval_acc:.4f}  \"\n","                        f\"val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n","\n","            ckpt_state = {\n","                \"epoch\": epoch + 1,\n","                \"model_state_dict\": model.state_dict(),\n","                \"optimizer_state_dict\": optimizer.state_dict(),\n","                \"scheduler_state_dict\": scheduler.state_dict() if scheduler else None,\n","                \"best_val_acc\": best_val_acc\n","            }\n","            # save latest checkpoint always\n","            save_checkpoint(ckpt_state, os.path.join(OUTPUT_DIR, \"latest.pth\"))\n","\n","            # save best model\n","            if val_acc > best_val_acc:\n","                best_val_acc = val_acc\n","                best_path = os.path.join(OUTPUT_DIR, f\"best_epoch_{epoch+1:03d}_valacc_{val_acc:.4f}.pth\")\n","                save_checkpoint(ckpt_state, best_path)\n","                logger.info(f\"Saved new best model to {best_path} (val_acc={val_acc:.4f})\")\n","\n","    except Exception as e:\n","        # Save latest on exception to avoid losing progress\n","        tb = traceback.format_exc()\n","        logger.error(f\"Training failed unexpectedly: {e}\\n{tb}\")\n","        try:\n","            save_checkpoint({\n","                \"epoch\": epoch + 1 if 'epoch' in locals() else 0,\n","                \"model_state_dict\": model.state_dict(),\n","                \"optimizer_state_dict\": optimizer.state_dict(),\n","                \"scheduler_state_dict\": scheduler.state_dict() if scheduler else None,\n","                \"best_val_acc\": best_val_acc\n","            }, os.path.join(OUTPUT_DIR, \"latest_on_error.pth\"))\n","            logger.info(\"Saved latest checkpoint to latest_on_error.pth\")\n","        except Exception as se:\n","            logger.error(f\"Failed to save checkpoint on error: {se}\")\n","        raise\n","\n","    # ---------------------- Final evaluation on test set (optional) ----------------------\n","    # If a best model was saved, load it for test evaluation\n","    best_ckpt = None\n","    best_files = sorted(glob.glob(os.path.join(OUTPUT_DIR, \"best_epoch_*.pth\")), key=os.path.getmtime, reverse=True)\n","    if best_files:\n","        best_ckpt = best_files[0]\n","    elif os.path.exists(os.path.join(OUTPUT_DIR, \"latest.pth\")):\n","        best_ckpt = os.path.join(OUTPUT_DIR, \"latest.pth\")\n","\n","    if best_ckpt:\n","        logger.info(f\"Loading best checkpoint for final evaluation: {best_ckpt}\")\n","        load_checkpoint(best_ckpt, model, device=DEVICE)\n","\n","    if test_loader is not None:\n","        test_loss, test_acc = eval_one_epoch(model, test_loader, criterion, DEVICE)\n","        logger.info(f\"TEST final: loss={test_loss:.4f}, acc={test_acc:.4f}\")\n","    else:\n","        logger.info(\"No test split provided - skipping final test evaluation.\")\n","\n","    # ---------------------- Save class map for inference convenience ----------------------\n","    if os.path.exists(CLASSES_CSV):\n","        logger.info(f\"classes CSV exists at {CLASSES_CSV}\")\n","    else:\n","        # write small classes CSV mapping if not present\n","        uniq = sorted(df[label_col].unique())\n","        classes_df = pd.DataFrame({\"class_index\": list(range(len(uniq))), \"class_name\": [str(x) for x in uniq]})\n","        classes_df.to_csv(CLASSES_CSV, index=False)\n","        logger.info(f\"Wrote fallback classes CSV to {CLASSES_CSV}\")\n","\n","    logger.info(\"Training script finished.\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6262,"status":"ok","timestamp":1760544315384,"user":{"displayName":"Carlos","userId":"17576890038933523144"},"user_tz":240},"id":"Q5zqte5GVJ_9","outputId":"2f5e31d9-76a2-4802-c5d9-db56e450199c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded checkpoint type: <class 'dict'>\n","Checkpoint contains keys: ['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'best_val_acc']\n"]}],"source":["'''!git config --global user.email \"he.carlitos@gmail.com\"\n","!git config --global user.name \"Carlos\"\n","!git add .\n","!git commit -m \"Ready to train\"\n","!git push https://cahehe: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@github.com/cahehe/fruit-image-classifier.git'''\n","# show current working directory and list files here\n","# show mount info + drive root listing\n","\n","#%cd Projects/\n","#%cd Fruits\\ Image\\ Classifier\n","#!git commit -m \"Ready to train\"\n","#!git push https://cahehe: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@github.com/cahehe/fruit-image-classifier.git"]},{"cell_type":"code","source":[],"metadata":{"id":"iqxG7mbznjz3"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"jupytext":{"formats":"ipynb,py:percent","main_language":"python"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}